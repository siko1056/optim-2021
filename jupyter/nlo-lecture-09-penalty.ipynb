{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1f34eaa-e274-415b-8ce6-d2ff19f78527",
   "metadata": {},
   "source": [
    "# Penalty methods\n",
    "\n",
    "In contrast to barrier methods,\n",
    "**penalty methods** solve a sequence of unconstrained optimization problems\n",
    "whose solution is usually infeasible to the original constrained problem.\n",
    "As this penalty is increased,\n",
    "the iterates are forced towards the feasible region."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6f3f6b-afc5-4f0b-a7ae-daf98140229a",
   "metadata": {},
   "source": [
    "Consider the equality-constrained problem\n",
    "\n",
    "$$\n",
    "\\begin{array}{ll}\n",
    "\\textrm{minimize}   & f(x)      \\\\\n",
    "\\textrm{subject to} & h(x) = 0, \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "where $h(x)$ is an $p$-dimensional vector,\n",
    "whose $j$-th component $h_{j}(x)$ is twice continuously differentiable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aaad452-f3c9-4825-a10f-87cf83e7195e",
   "metadata": {},
   "source": [
    "The best-known penalty is the **quadratic-loss function**\n",
    "\n",
    "$$\n",
    "\\psi(x) := \\frac{1}{2} \\sum_{j = 1}^{p} h_{j}(x)^{2}\n",
    "= \\frac{1}{2} h(x)^{T}h(x).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c838fc21-67cf-4ae7-8fee-6c78ba165e5d",
   "metadata": {},
   "source": [
    "The weight of the penalty is controlled by a positive **penalty parameter $\\rho$**.\n",
    "The penalty method consists of solving a sequence of\n",
    "**unconstrained minimization problems** of the form\n",
    "\n",
    "$$\n",
    "\\min\\limits_{x} \\pi(x,\\rho^{k}) = f(x) + \\rho^{k}\\psi(x)\n",
    "$$\n",
    "\n",
    "for an increasing sequence $\\{ \\rho^{k} \\}$ of positive values tending to infinity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4babb9d-3f4b-4c9a-accf-b53315adcb01",
   "metadata": {},
   "source": [
    "Penalty methods share many of the properties of barrier methods.\n",
    "Under appropriate conditions,\n",
    "the sequence of penalty function minimizers defines a continuous trajectory.\n",
    "In the latter case,\n",
    "it is possible to get estimates of the Lagrange multipliers at the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf70ada-9c7f-47c0-972f-e8cba06ac85b",
   "metadata": {},
   "source": [
    "Consider the quadratic-loss penalty function\n",
    "\n",
    "$$\n",
    "\\pi(x,\\rho) = f(x) + \\frac{1}{2} \\rho \\sum_{j = 1}^{p} h_{j}(x)^{2}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea87483-199d-4448-b04e-e31141744a44",
   "metadata": {},
   "source": [
    "Its minimizer $x(\\rho)$ satisfies\n",
    "\n",
    "$$\n",
    "\\nabla_{x} \\pi(x(\\rho),\\rho)\n",
    "= \\nabla f(x(\\rho)) + \\rho \\sum_{j = 1}^{p} \\nabla h_{j}(x(\\rho)) h_{j}(x(\\rho)) = 0.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae796dd-a218-4e41-afa0-e87d3b9458b8",
   "metadata": {},
   "source": [
    "Defining $\\lambda_{j}(\\rho) := -\\rho \\cdot h_{j}(x(\\rho))$ one obtains\n",
    "\n",
    "$$\n",
    "\\nabla f(x(\\rho)) - \\sum_{j = 1}^{p} \\lambda_{j}(\\rho) \\nabla h_{j}(x(\\rho)) = 0.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016593a1-e099-42b1-ad70-fccf52dfc592",
   "metadata": {},
   "source": [
    "If $x(\\rho)$ converges to a solution $x^{*}$\n",
    "that is a regular point of the constraints,\n",
    "then $\\lambda(\\rho)$ converges to the Lagrange multiplier $\\lambda^{*}$\n",
    "associated with $x^{*}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cdf66a-c6a4-43cc-8877-448062224fe8",
   "metadata": {},
   "source": [
    "Penalty functions suffer from the same problems of ill-conditioning as barrier functions.\n",
    "As the penalty parameter increases,\n",
    "the condition number of the Hessian matrix of $\\pi(x(\\rho), \\rho)$ increases,\n",
    "tending to $\\infty$ as $\\rho \\to \\infty$.\n",
    "Therefore the unconstrained minimization problems can become increasingly difficult to solve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c554cd-ed21-4863-a807-d63a5bf950c4",
   "metadata": {},
   "source": [
    "## PM: Example 1\n",
    "\n",
    "Consider the problem\n",
    "\n",
    "$$\n",
    "\\begin{array}{lll}\n",
    "\\textrm{minimize}   & f(x) =& -x_{1}x_{2}    \\\\\n",
    "\\textrm{subject to} & h(x) =& x_{1} + 2 x_{2} - 4 = 0.\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45fd63d-bc3b-4236-85a6-3056f0b787dd",
   "metadata": {},
   "source": [
    "Then the penalty method solves a sequence of unconstrained minimization problems\n",
    "\n",
    "$$\n",
    "\\min\\limits_{x} \\pi(x,\\rho^{k}) = -x_{1}x_{2} + \\frac{1}{2} \\rho^{k} (x_{1} + 2 x_{2} - 4)^{2}\n",
    "$$\n",
    "\n",
    "for increasing values $\\rho^{k}$.\n",
    "The necessary conditions for optimality are\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "-x_{2} + \\rho(x_{1} + 2 x_{2} - 4) &= 0 \\\\\n",
    "-x_{1} + 2\\rho(x_{1} + 2 x_{2} - 4) &= 0.\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37b0ab8-6838-473f-b4c8-910fe7476652",
   "metadata": {},
   "source": [
    "For $\\rho > 1/4$ this yields the solution\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "x_{1}(\\rho) &= \\frac{8 \\rho}{4 \\rho - 1}, \\\\\n",
    "x_{2}(\\rho) &= \\frac{4 \\rho}{4 \\rho - 1},\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "which is a local as well as a global minimizer.\n",
    "(The unconstrained problem has no minimum if $\\rho \\leq 1/4$.)\n",
    "Note that $x(\\rho)$ is infeasible to the original constrained problem,\n",
    "since\n",
    "\n",
    "$$\n",
    "h(x(\\rho)) = x_{1} + 2x_{2} - 4 = \\frac{16 \\rho}{4 \\rho - 1} - 4 = \\frac{4 \\rho}{4 \\rho - 1}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfe106f-df81-4ef2-a6b8-c5db7f58b6b7",
   "metadata": {},
   "source": [
    "At any solution $x(\\rho)$ we can define a Lagrange multiplier estimate\n",
    "\n",
    "$$\n",
    "\\lambda = -\\rho \\cdot h(x(\\rho)) = \\frac{-4 \\rho}{4 \\rho - 1}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecab8ab-a69b-42e9-a68e-a5f3eb50ded1",
   "metadata": {},
   "source": [
    "As $\\rho$ tends to $\\infty$ one obtains\n",
    "\n",
    "$$\n",
    "\\lim_{\\rho \\to \\infty} x_{1}(\\rho)\n",
    "= \\lim_{\\rho \\to \\infty} \\frac{2}{1 - 1/4\\rho} = 2, \\qquad\n",
    "\\lim_{\\rho \\to \\infty} x_{2}(\\rho)\n",
    "= \\lim_{\\rho \\to \\infty} \\frac{1}{1 - 1/4\\rho} = 1,\n",
    "$$\n",
    "\n",
    "and indeed $x^{*} = (2, 1)^{T}$ is the minimizer for the constrained problem.\n",
    "Further,\n",
    "\n",
    "$$\n",
    "\\lim_{\\rho \\to \\infty} \\lambda(\\rho)\n",
    "= \\lim_{\\rho \\to \\infty} \\frac{-1}{1 - 1/4\\rho} = -1,\n",
    "$$\n",
    "\n",
    "and indeed $\\lambda^{*} = -1$ is the Lagrange multiplier at $x^{*}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa2950d-fe11-460d-bb27-11b2c2e09683",
   "metadata": {},
   "source": [
    "The ill-conditioning of the penalty function is demonstrated\n",
    "by the Hessian matrix at $x(\\rho)$:\n",
    "\n",
    "$$\n",
    "\\nabla_{x}^{2} \\pi(x(\\rho),\\rho) =\n",
    "\\begin{pmatrix}\n",
    "\\rho      & 2\\rho - 1 \\\\\n",
    "2\\rho - 1 & 4\\rho\n",
    "\\end{pmatrix}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa4f100-0b5b-429d-b587-341aadfaca2d",
   "metadata": {},
   "source": [
    "It can be shown that its condition number is approximately $25 \\rho / 4$.\n",
    "When $\\rho$ is large,\n",
    "the Hessian matrix is ill-conditioned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0064dd6-71fd-4518-a003-8fa9f7ebd6c6",
   "metadata": {},
   "source": [
    "It is also possible to apply penalty methods to problems with inequality constraints.\n",
    "Consider for example the problem\n",
    "\n",
    "$$\n",
    "\\begin{array}{ll}\n",
    "\\textrm{minimize}   & f(x)      \\\\\n",
    "\\textrm{subject to} & g_{i}(x) \\geq 0, \\quad i = 1, \\ldots, m. \\\\\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f57ad8-39c4-4871-8cbf-5ef30273d48a",
   "metadata": {},
   "source": [
    "For example, the **quadratic-loss penalty** in this case is\n",
    "\n",
    "$$\n",
    "\\psi(x) := \\frac{1}{2} \\sum_{i = 1}^{m} \\left[ \\min (g_{i}(x), 0) \\right]^{2}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba2a034-8746-4c2d-9bf0-5ce2e6ee809c",
   "metadata": {},
   "source": [
    "This function has continuous first derivatives\n",
    "\n",
    "$$\n",
    "\\nabla \\psi(x) = \\sum_{i = 1}^{m} \\left[ \\min (g_{i}(x), 0) \\right] \\nabla g_{i}(x),\n",
    "$$\n",
    "\n",
    "but its second derivatives can be discontinuous at points\n",
    "where some constraint $g_{i}$ is satisfied exactly.\n",
    "Hence, a careful implementation is necessary.\n",
    "One cannot safely use Newton's method to minimize the function.\n",
    "For this reason,\n",
    "straightforward penalty methods have not been widely used\n",
    "for solving general inequality-constrained problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a268c3-e57b-485e-a5c1-72de1eca583a",
   "metadata": {},
   "source": [
    "For a convergence discussion of penalty methods, see {cite}`Griva2008` (chapter 16.2.3)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Octave",
   "language": "octave",
   "name": "octave"
  },
  "language_info": {
   "file_extension": ".m",
   "help_links": [
    {
     "text": "GNU Octave",
     "url": "https://www.gnu.org/software/octave/support.html"
    },
    {
     "text": "Octave Kernel",
     "url": "https://github.com/Calysto/octave_kernel"
    },
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-octave",
   "name": "octave",
   "version": "6.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
