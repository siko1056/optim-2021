{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6eb784d6-c296-490a-b8f3-2b716d647ebe",
   "metadata": {},
   "source": [
    "# Constrained minimization algorithms\n",
    "\n",
    "Some of the algorithms and techniques\n",
    "used to find local minima\n",
    "of **unconstrained** optimization problems\n",
    "can be applied *mutatis mutandis*\n",
    "for the **constrained** problem case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d13886-c530-4b33-bb3b-b94066414d4f",
   "metadata": {},
   "source": [
    "## Sequential Quadratic Programming (SQP)\n",
    "\n",
    "For the sake of simplicity\n",
    "the equality constrained minimization problem is considered:\n",
    "\n",
    "$$\n",
    "\\begin{array}{lll}\n",
    "\\textrm{minimize}   & f(x)          & \\\\\n",
    "\\textrm{subject to} & h_{j}(x) = 0, & j = 1, \\ldots, p, \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "with **optimization variable** $x \\in \\mathbb{R}^{n}$ and\n",
    "twice continuously differentiable\n",
    "**objective and constraint functions**\n",
    "$f, h_{j} \\in C^{2}(\\mathbb{R}^{n}, \\mathbb{R})$,\n",
    "$h := (h_{1}, \\ldots, h_{p})^{T} \\in C^{2}(\\mathbb{R}^{n}, \\mathbb{R}^{p})$.\n",
    "\n",
    "The corresponding **Lagrangian** is:\n",
    "\n",
    "$$\n",
    "L(x, \\mu) := f(x) + \\sum_{j = 1}^{p} \\mu_{j} h_{j}(x),\n",
    "$$\n",
    "\n",
    "and **KKT optimality conditions**:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\nabla_{x} L(x^{*}, \\mu^{*})\n",
    "&=\\; \\nabla f(x^{*}) + \\sum_{j = 1}^{p} \\mu_{j}^{*} \\nabla h_{j}(x^{*})\n",
    "&=\\; 0 & \\\\\n",
    "\\nabla_{\\mu} L(x^{*}, \\mu^{*})\n",
    "&=\\; ( h_{j}(x^{*}) ) = h(x^{*})\n",
    "&=\\; 0 &,\n",
    "\\quad j = 1, \\ldots, p\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79077cf-eaff-4b81-970c-746d1b3afc70",
   "metadata": {},
   "source": [
    "Again the goal is to perform an iteration\n",
    "\n",
    "$$\n",
    "\\mathbf{x}^{k+1} = \\mathbf{x}^{k} + \\alpha \\mathbf{d}^{k}\n",
    "$$\n",
    "\n",
    "with $\\mathbf{x} = (x, \\mu)^{T}$,\n",
    "which converges from a starting point $\\mathbf{x}^{0}$\n",
    "to a local minimum $\\mathbf{x}^{*}$\n",
    "(a stationary point of the KKT optimality conditions)\n",
    "choosing a **descent direction** $\\mathbf{d} = (\\Delta x, \\Delta \\mu)^{T}$\n",
    "and a **step size** $\\alpha$ in each step\n",
    "(cf. [Gradient methods](gradient_methods))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a80f09b-460a-4a96-bff0-49fcc4033b89",
   "metadata": {},
   "source": [
    "Using [**Newton's method**](Newtons_method)\n",
    "(quadratic Taylor-approximation of the Lagrangian $L(x, \\mu)$)\n",
    "to determine the descent direction,\n",
    "results in solving the following system of non-linear equations:\n",
    "\n",
    "$$\n",
    "\\nabla^{2} L(x, \\mu) \\mathbf{d} = -\\nabla L(x, \\mu)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "\\nabla^{2}_{x,x} L(x, \\mu)     & \\nabla^{2}_{x,\\mu} L(x, \\mu) \\\\\n",
    "\\nabla^{2}_{\\mu,x} L(x, \\mu) & \\nabla^{2}_{\\mu,\\mu} L(x, \\mu)\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix} \\Delta x \\\\ \\Delta \\mu \\end{pmatrix}\n",
    "=\n",
    "-\\begin{pmatrix}\n",
    "\\nabla_{x} L(x, \\mu) \\\\\n",
    "\\nabla_{\\mu} L(x, \\mu)\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25910bdb-86db-485d-878d-b9952f98ce82",
   "metadata": {},
   "source": [
    "This **Hessian matrix** has a certain structure:\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "Q & B^{T} \\\\\n",
    "B & 0\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix} \\Delta x \\\\ \\Delta \\mu \\end{pmatrix}\n",
    "= -\\begin{pmatrix} \\nabla f(x) + B^{T} \\mu \\\\ h(x) \\end{pmatrix}\n",
    "= -\\begin{pmatrix} \\nabla_{x} L(x, \\mu)    \\\\ h(x) \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "- $Q := \\nabla^{2}_{x,x} L(x, \\mu) = \\nabla^{2} f(x) + \\sum_{j = 1}^{p} \\mu_{j} \\nabla^{2} h_{j}(x)$.\n",
    "\n",
    "- $B := \\nabla^{2}_{\\mu,x} L(x, \\mu) = $\n",
    "  $\\begin{pmatrix} \\nabla^{T} h_{1}(x) \\\\ \\vdots \\\\ \\nabla^{T} h_{p}(x) \\end{pmatrix}$\n",
    "  is the **Jacobian matrix** of $h(x)$.\n",
    "\n",
    "- $B^{T} = \\nabla^{2}_{x,\\mu} L(x, \\mu) = \\begin{pmatrix} \\nabla h_{1}(x) & \\ldots & \\nabla h_{p}(x) \\end{pmatrix}$\n",
    "  is the transposed **Jacobian matrix** of $h(x)$.\n",
    "\n",
    "- $\\nabla^{2}_{\\mu,\\mu} L(x, \\mu) = 0$ is a zero matrix,\n",
    "  as $L(x, \\mu)$ is linear in $\\mu$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7044bb-5283-438f-9077-396813851e29",
   "metadata": {},
   "source": [
    "The derived Newton-equation happens to be identical\n",
    "to the KKT optimality conditions\n",
    "of the following quadratic optimization problem:\n",
    "\n",
    "$$\n",
    "\\begin{array}{lll}\n",
    "\\textrm{minimize}\n",
    "& F(\\Delta x)\n",
    "&:= \\frac{1}{2} (\\Delta x)^{T} Q \\Delta x + \\nabla_{x} L(x,\\mu)^{T} \\Delta x \\\\\n",
    "\\textrm{subject to}\n",
    "& H(\\Delta x)\n",
    "&:= B \\Delta x + h(x) = 0.\n",
    "\\end{array}\n",
    "$$(SQP_sub_problem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381a449f-ac86-4fc3-9e51-7bde7041f309",
   "metadata": {},
   "source": [
    "By choosing the Lagrange multipliers $\\lambda = \\Delta \\mu$ for the equality constraints,\n",
    "the corresponding Lagrangian is:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\Delta x,\\lambda) = F(\\Delta x) + H(\\Delta x)^{T} \\lambda\n",
    "$$\n",
    "\n",
    "and the KKT optimality conditions:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\nabla_{(\\Delta x)} \\mathcal{L}(\\Delta x,\\lambda)\n",
    "&:=& Q \\Delta x +  \\nabla_{x} L(x,\\mu) + B^{T} \\lambda &= 0, \\\\\n",
    "H(\\Delta x) = \\nabla_{\\lambda} \\mathcal{L}(\\Delta x,\\lambda)\n",
    "&:=& B \\Delta x + h(x) &= 0.\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a49aaae-3f51-41cc-8776-bc5cb75cb13c",
   "metadata": {},
   "source": [
    "or written in matrix notation and regarding $\\lambda = \\Delta \\mu$:\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "Q & B^{T} \\\\\n",
    "B & 0\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix} \\Delta x \\\\ \\Delta \\mu \\end{pmatrix}\n",
    "= -\\begin{pmatrix} \\nabla_{x} L(x,\\mu) \\\\ h(x) \\end{pmatrix}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e235862-2156-4fb0-911e-e71a997283f5",
   "metadata": {},
   "source": [
    "Summarizing:\n",
    "\n",
    "- SQP methods solve a sequence of **quadratic optimization sub-problems**\n",
    "  (quadratic objective function and linearized constraints).\n",
    "\n",
    "- In the unconstrained case, SQP reduces to **Newton's method** for finding a stationary point $\\nabla f(x) = 0$.\n",
    "\n",
    "- In the only equality constrained case, the SQP method is equivalent to applying Newton's method to the KKT optimality conditions.\n",
    "\n",
    "- Extensions for equality and inequality constraints exist,\n",
    "  but are not discussed in this seminar.\n",
    "\n",
    "- Similar problems and limitations\n",
    "  as discussed in the section about [**Newton's method**](Newtons_method)\n",
    "  apply to the SQP method.\n",
    "  \n",
    "  - Computing the Hessian matrix is expensive.\n",
    "  - If the Hessian matrix is not symmetric positive definite\n",
    "    or the constraints are not linear independent (LICQ)\n",
    "    during the iteration,\n",
    "    convergence cannot be guaranteed.\n",
    "\n",
    "- See exercise [RM04](RM04) for an application example."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Octave",
   "language": "octave",
   "name": "octave"
  },
  "language_info": {
   "file_extension": ".m",
   "help_links": [
    {
     "text": "GNU Octave",
     "url": "https://www.gnu.org/software/octave/support.html"
    },
    {
     "text": "Octave Kernel",
     "url": "https://github.com/Calysto/octave_kernel"
    },
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-octave",
   "name": "octave",
   "version": "6.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
